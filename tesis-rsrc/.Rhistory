yd <- dnorm(xx, 0.42, 0.5)
yc <- pnorm(xx, 0.42, 0.5)
plot(xx, yd, type = "l", axes = FALSE, ylim = c(0,1), xlim = c(-1.5, 2),
xlab = "", ylab = "", col = "gray", lwd = 2,
main = "Ordered probit")
lines(xx, yc, type = "l", lwd = 2)
usr <- par("usr")
arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)
arrows(-1.5, usr[3], -1.5, usr[4], length = 0.1, angle = 0)
text(-1.55, usr[4], "1", adj = c(1, 1), cex = tc)
segments(-1.5, 1, 2, 1, lty = 2, lwd = 0)
segments(0, 0, 0, yc[xx==0], lty = 2, lwd = 0)
text(0.15, 0.03, expression(c[0]), adj = c(1, 0), cex = tc)
segments(1, 0, 1, yc[xx==1], lty = 2, lwd = 0)
text(1.15, 0.03, expression(c[1]), adj = c(1, 0), cex = tc)
arrows(0, yc[xx==0], -1.5, yc[xx==0], length=0.1)
arrows(1, yc[xx==1], -1.5, yc[xx==1], length=0.1)
text(-1.35, yc[xx==0]*0.45, expression(p^0), adj = c(1, 0), cex = tc)
text(-1.35, (yc[xx==1]-yc[xx==0])*0.45+yc[xx==0], expression(p^1), adj = c(1, 0), cex = tc)
text(-1.35, (1-yc[xx==1])*0.4+yc[xx==1], expression(p^2), adj = c(1, 0), cex = tc)
###
dev.off()
w <- 800*1.2*1.2
h <- 500*1.2
tc <- 2.6
png("D:/gitrepos/statesis/latex/img/oprobit.png", width = w, height = h)
###
par(mar = c(0, 0, 2.0, 0))
xx <- seq(-2.5, 2.5, len = 101)
yd <- dnorm(xx, 0.42, 0.5)
yc <- pnorm(xx, 0.42, 0.5)
plot(xx, yd, type = "l", axes = FALSE, ylim = c(0,1), xlim = c(-1.5, 2),
xlab = "", ylab = "", col = "gray", lwd = 2,
main = "Ordered probit")
lines(xx, yc, type = "l", lwd = 2)
usr <- par("usr")
arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)
arrows(-1.5, usr[3], -1.5, usr[4], length = 0.1, angle = 0)
text(-1.55, usr[4], "1", adj = c(1, 1), cex = tc)
segments(-1.5, 1, 2, 1, lty = 2, lwd = 0)
segments(0, 0, 0, yc[xx==0], lty = 2, lwd = 0)
text(0.15, 0.03, expression(c[0]), adj = c(1, 0), cex = tc)
segments(1, 0, 1, yc[xx==1], lty = 2, lwd = 0)
text(1.15, 0.03, expression(c[1]), adj = c(1, 0), cex = tc)
arrows(0, yc[xx==0], -1.5, yc[xx==0], length=0.1)
arrows(1, yc[xx==1], -1.5, yc[xx==1], length=0.1)
text(-1.35, yc[xx==0]*0.42, expression(p^0), adj = c(1, 0), cex = tc)
text(-1.35, (yc[xx==1]-yc[xx==0])*0.45+yc[xx==0], expression(p^1), adj = c(1, 0), cex = tc)
text(-1.35, (1-yc[xx==1])*0.36+yc[xx==1], expression(p^2), adj = c(1, 0), cex = tc)
###
dev.off()
w <- 800*1.2*1.2
h <- 500*1.2
tc <- 2.6
png("D:/gitrepos/statesis/latex/img/oprobit.png", width = w, height = h)
###
par(mar = c(0, 0, 2.0, 0))
xx <- seq(-2.5, 2.5, len = 101)
yd <- dnorm(xx, 0.42, 0.5)
yc <- pnorm(xx, 0.42, 0.5)
plot(xx, yd, type = "l", axes = FALSE, ylim = c(0,1), xlim = c(-1.5, 2),
xlab = "", ylab = "", col = "gray", lwd = 2,
main = "Ordered probit")
lines(xx, yc, type = "l", lwd = 2)
usr <- par("usr")
arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)
arrows(-1.5, usr[3], -1.5, usr[4], length = 0.1, angle = 0)
text(-1.55, usr[4], "1", adj = c(1, 1), cex = tc)
segments(-1.5, 1, 2, 1, lty = 2, lwd = 0)
segments(0, 0, 0, yc[xx==0], lty = 2, lwd = 0)
text(0.15, 0.03, expression(c[0]), adj = c(1, 0), cex = tc)
segments(1, 0, 1, yc[xx==1], lty = 2, lwd = 0)
text(1.15, 0.03, expression(c[1]), adj = c(1, 0), cex = tc)
arrows(0, yc[xx==0], -1.5, yc[xx==0], length=0.1)
arrows(1, yc[xx==1], -1.5, yc[xx==1], length=0.1)
text(-1.35, yc[xx==0]*0.42, expression(p^0), adj = c(1, 0), cex = tc)
text(-1.35, (yc[xx==1]-yc[xx==0])*0.45+yc[xx==0], expression(p^1), adj = c(1, 0), cex = tc)
text(-1.35, (1-yc[xx==1])*0.32+yc[xx==1], expression(p^2), adj = c(1, 0), cex = tc)
###
dev.off()
w <- 800*1.2*1.2
h <- 500*1.2
tc <- 2.6
png("D:/gitrepos/statesis/latex/img/oprobit.png", width = w, height = h)
###
par(mar = c(0, 0, 0, 0))
xx <- seq(-2.5, 2.5, len = 101)
yd <- dnorm(xx, 0.42, 0.5)
yc <- pnorm(xx, 0.42, 0.5)
plot(xx, yd, type = "l", axes = FALSE, ylim = c(0,1), xlim = c(-1.5, 2),
xlab = "", ylab = "", col = "gray", lwd = 2)
lines(xx, yc, type = "l", lwd = 2)
usr <- par("usr")
arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)
arrows(-1.5, usr[3], -1.5, usr[4], length = 0.1, angle = 0)
text(-1.55, usr[4], "1", adj = c(1, 1), cex = tc)
segments(-1.5, 1, 2, 1, lty = 2, lwd = 0)
segments(0, 0, 0, yc[xx==0], lty = 2, lwd = 0)
text(0.15, 0.03, expression(c[0]), adj = c(1, 0), cex = tc)
segments(1, 0, 1, yc[xx==1], lty = 2, lwd = 0)
text(1.15, 0.03, expression(c[1]), adj = c(1, 0), cex = tc)
arrows(0, yc[xx==0], -1.5, yc[xx==0], length=0.1)
arrows(1, yc[xx==1], -1.5, yc[xx==1], length=0.1)
text(-1.35, yc[xx==0]*0.42, expression(p^0), adj = c(1, 0), cex = tc)
text(-1.35, (yc[xx==1]-yc[xx==0])*0.45+yc[xx==0], expression(p^1), adj = c(1, 0), cex = tc)
text(-1.35, (1-yc[xx==1])*0.32+yc[xx==1], expression(p^2), adj = c(1, 0), cex = tc)
###
dev.off()
w <- 800*1.2*1.2
h <- 500*1.2
tc <- 2.6
par(mar = c(0, 0, 0, 0))
xx <- seq(-2.5, 2.5, len = 101)
yd <- dnorm(xx, 0.42, 0.5)
yc <- pnorm(xx, 0.42, 0.5)
plot(xx, yd, type = "l", axes = FALSE, ylim = c(0,1), xlim = c(-1.5, 2),
xlab = "", ylab = "", col = "gray", lwd = 2)
lines(xx, yc, type = "l", lwd = 2)
usr <- par("usr")
arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)
arrows(-1.5, usr[3], -1.5, usr[4], length = 0.1, angle = 0)
text(-1.55, usr[4], "1", adj = c(1, 1), cex = tc)
segments(-1.5, 1, 2, 1, lty = 2, lwd = 0)
segments(0, 0, 0, yc[xx==0], lty = 2, lwd = 0)
text(0.15, 0.03, expression(c[0]), adj = c(1, 0), cex = tc)
segments(1, 0, 1, yc[xx==1], lty = 2, lwd = 0)
text(1.15, 0.03, expression(c[1]), adj = c(1, 0), cex = tc)
arrows(0, yc[xx==0], -1.5, yc[xx==0], length=0.1)
arrows(1, yc[xx==1], -1.5, yc[xx==1], length=0.1)
text(-1.35, yc[xx==0]*0.42, expression(p^0), adj = c(1, 0), cex = tc)
text(-1.35, (yc[xx==1]-yc[xx==0])*0.45+yc[xx==0], expression(p^1), adj = c(1, 0), cex = tc)
text(-1.35, (1-yc[xx==1])*0.32+yc[xx==1], expression(p^2), adj = c(1, 0), cex = tc)
library(rio)
pica <- import("D:/Downloads/fullmergebl.dta")
pica
head(pica)
dim(pica)
library(zoib)
install.packages("zoib")
library(zoib)
data("AlcoholUse")
data("AlcoholUse", package = "zoib")
AlcoholUse
head(AlcoholUse)
AlcoholUse[1:20]
AlcoholUse[1:20,]
?AlcoholUse
library(zoib)
data("AlcoholUse", package = "zoib")
table(AlcoholUse$Days)
?AlcoholUse
library(zoib)
library(data.table)
library(magrittr)
data("AlcoholUse", package = "zoib")
AlcoholUse %<>% data.table
AlcoholUse
AlcoholUse[,.(Percentage=mean(Percentage)),.(Days)]
AlcoholUse[,.(Percentage=sum(Percentage)),.(Days)]
AlcoholUse[1:20]
AlcoholUse[1:30]
AlcoholUse[1:24,.(Percentage=sum(Percentage))]
qnorm(0,0,1)
qnorm(1,0,1)
curve(qnorm(,0,1))
curve(qnorm(c,0,1))
curve(qnorm(x,0,1))
curve(qnorm(x,0,1))
curve(qnorm(x,0,1))
curve(qnorm(x,0,2))
curve(qnorm(x,0,3))
curve(qnorm(x,0,1))
curve(qnorm(x,0,2))
curve(qnorm(x,0,1))
library(rio)
library(data.table)
cs1 <- import("D:/CHAMBA/Unicef/productos/p3_prueba/Modulo414/CSALUD01.sav", setclass = "data.table")
cs1
install.packages("haven")
install.packages("haven")
library(rio)
library(data.table)
cs1 <- import("D:/CHAMBA/Unicef/productos/p3_prueba/Modulo414/CSALUD01.sav", setclass = "data.table")
cs1
md5(cs1)
md5sum
library(tools)
md5sum(cs1)
library(rio)
library(data.table)
cs1 <- import("D:/CHAMBA/Unicef/productos/p3_prueba/Modulo414/CSALUD01.sav", setclass = "data.table")
apply(cs1, 2, table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% unlist %>% table
library(magrittr)
library(rio)
library(data.table)
cs1 <- import("D:/CHAMBA/Unicef/productos/p3_prueba/Modulo414/CSALUD01.sav", setclass = "data.table")
apply(cs1, 2, table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% unlist %>% table
library(magrittr)
library(rio)
library(data.table)
cs1 <- import("D:/CHAMBA/Unicef/productos/p3_prueba/Modulo414/CSALUD01.sav", setclass = "data.table")
apply(cs1, 2, table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>% lapply(table) %>%  unlist %>% table
library(rio)
import("C:/Users/Personal/Desktop/Part_III_Weighting_DHS_Data_Stata/ZZIR61FL.DTA", setclass = "data.table") -> dhsdta
dhsdta
dhs[,.(v005, v021, v022, v025)]
dhsdta[,.(v005, v021, v022, v025)]
write.dta
library(foregin)
library(foreign)
write.dta
write.dta(dhsdta[,.(v005, v021, v022, v025)], "dhs.dta")
getwd()
sample(0:3, 20, replace =T)
sample(0:3, 20, replace = T)
set.seed(13)
y <- sample(0:3, 20, replace = T)
y
table(y)
lapply(0:3, function(x)which(y==x))
k <- lapply(0:3, function(x)which(y==x))
lapply(k, function(x)y[x])
ll <- rnorm(20)
ll
lapply(k,
function(x){
pk <- ll[x]
mk <- length(y[x])
N <- length(y)
((mk - N*pk)/sqrt(N*pk))**2
}
)
ll
ll <- exp(10)
ll <- exp(20)
ll
ll <- rexp(20)
ll
ll <- -rexp(20)
ll
exp(ll)
range(exp(ll))
lapply(k,
function(x){
pk <- exp(ll[x])
mk <- length(y[x])
N <- length(y)
((mk - N*pk)/sqrt(N*pk))**2
}
)
lapply(k,
function(x){
pk <- exp(ll[x])
mk <- length(y[x])
N <- length(y)
sum(((mk - N*pk)/sqrt(N*pk))**2)
})
gshs_file <- "D:/datasets/gshs/2010/PEH2010_Public_Use.sav"
library(rio)
library(haven)
library(data.table)
gshs_file <- "D:/datasets/gshs/2010/PEH2010_Public_Use.sav"
import(gshs_file, setclass = "data.table")
gshs <- import(gshs_file, setclass = "data.table")
gshs[,1:10]
gshs$Q1
library(rio)
library(haven)
library(data.table)
# gshs_file <- "D:/datasets/gshs/2010/PEH2010_Public_Use.sav"
# gshs <- import(gshs_file, setclass = "data.table")
pisa_cog_file <- "D:/datasets/pisa/2015/PUF_SPSS_COMBINED_CMB_STU_COG/CY6_MS_CMB_STU_COG.sav"
pisa_cog <- import(pisa_cog_file, setclass = "data.table")
pisa_cog
gc()
library(rio)
library(haven)
library(data.table)
?import
read_spss()
read_spss
read_sav
df_parse_sav_file
library(drake)
install.packages("drake")
library(drake)
library(rstan)
?sampling
library(drake)
seed_plan <- drake_plan(
seed1 = sample.int(.Machine$integer.max, 1),
seed2 = sample.int(.Machine$integer.max, 1),
)
make(seed_plan)
library(drake)
seed_plan <- drake_plan(
seed1 = sample.int(.Machine$integer.max, 1),
seed2 = sample.int(.Machine$integer.max, 1),
)
make(seed_plan)
install.packages("sparklyr")
library(sparklyr)
spark_install(version = "2.3.2")
library(sparklyr)
#spark_install(version = "2.3.2")
library(sparkhaven)
install.packages("sparkhaven")
library(devtools)
devtools::install_github("emaasit/sparkhaven")
library(sparklyr)
#spark_install(version = "2.3.2")
library(sparkhaven)
library(sparklyr)
#spark_install(version = "2.3.2")
library(sparkhaven)
library(haven)
?read_sas
read_sas
read_spss
?switch
tools::file_ext("bestlog1h.rdata")
tools::file_ext("bestlog1h.Rdata")
tolower(tools::file_ext("bestlog1h.Rdata"))
read_sav
?readr
readr
readr::datasource()
?readr::datasource
haven:::df_parse_sav_file()
haven:::df_parse_sav_file
?.Call
haven:::df_parse_sav_raw
read_dta
haven:::df_parse_dta_file()
haven:::df_parse_dta_file
?spark_connect
sc <- spark_connect(master = "local")
sc <- spark_connect(master = "local")
library(sparklyr)
#spark_install(version = "2.3.2")
library(sparkhaven)
sc <- spark_connect(master = "local")
library(sparklyr)
#spark_install(version = "2.3.2")
library(sparkhaven)
sc <- spark_connect(master = "local")
spark_uninstall(version = "2.3.2")
spark_uninstall()
?spark_uninstall
spark_available_versions()
spark_available_versions(show_hadoop = T)
spark_uninstall(version = "2.3.2", hadoop_version = "2.7")
spark_uninstall(version = "2.3.2", hadoop_version = "2.6")
library(sparklyr)
spark_install(version = "2.0.0")
library(sparkhaven)
sc <- spark_connect(master = "local")
getwd()
sc <- spark_connect(master = "local")
sc <- spark_connect(master = "local")
qq2 <- haven::read_sas("D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat")
qq2
?system.file
system.file("extdata", "mtcars.sas7bdat", package = "sparkhaven")
system.file("D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat", package = "sparkhaven")
system.file("D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat")
system.file("extdata", "mtcars.sas7bdat", package = "sparkhaven")
system.file("D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat")
library(sparkhaven)
system.file("extdata", "mtcars.sas7bdat", package = "sparkhaven")
?spark_read_sas
sparkhaven:::spark_read_sas
?sparkhaven:::spark_read_sas
filename
qq2_df <- sparkhaven:::spark_read_sas(sc, path = filename, table = "sas_qq2")
qq2_df <- sparkhaven:::spark_read_sas(sc, path = filename)
qq2_df <- sparkhaven:::spark_read_sas(sc, path = filename, name = "sas_qq2")
src_tbls
??src_tbls
sparkhaven:::spark_read_sas
spark_remove_table_if_exists
??spark_remove_table_if_exists
sparklyr::spark_remove_table_if_exist
sparklyr:::spark_remove_table_if_exists
sparklyr:::hive_context
sparklyr:::src_tbls
src_tbls
sparklyr::src_tbls
sparklyr:::src_tbls
dplyr::src_tbls
src_tbls <- dplyr::src_tbls
qq2_df <- sparkhaven:::spark_read_sas(sc, path = filename, name = "sas_qq2", overwrite = FALSE)
sparkhaven:::spark_read_sas
library(sparklyr)
# spark_available_versions(show_hadoop = T)
# spark_install(version = "2.0.0")
library(sparkhaven)
sc <- spark_connect(master = "local")
# me invente esto file:///C:/Users/Personal/.m2/repository/saurfang/spark-sas7bdat/1.1.4-s_2.11/spark-sas7bdat-1.1.4-s_2.11.jar LMAO
# source: spark-packages.org/package/saurfang/spark-sas7bdat
# (cambiar nombre del archivo jiojio)
#mtcars_file <- system.file("extdata", "mtcars.sas7bdat", package = "sparkhaven")
# Primero probemos con un archivo chiqui
filename <- "D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat"
# 519 334 x 21
#qq2 <- haven::read_sas(filename)
# Carga sin problemas, ahora tratemos de cargarlo en Spark
qq2_df <- sparkhaven:::spark_read_sas(sc, path = filename, name = "sas_qq2", overwrite = FALSE)
spark_available_versions(show_hadoop = T)
spark_uninstall(version = "2.0.0", hadoop_version = "2.7")
library(haven)
flt_file <- "D:/datasets/pisa/2015/PUF_SAS_COMBINED_CMB_STU_FLT/cy6_ms_cmb_stu_flt.sas7bdat"
flt <- read_sas(flt_file)
flt
library(dplyr)
flt %>% select(CNT == "PER")
flt %>% filter(CNT == "PER")
flt <- read_sas(flt_file) %>% filter(CNT == "PER")
flt
dim(flt)
write.csv(flt, "D:/datasets/pisa/2015/CSV/flt_per.csv", row.names = FALSE)
qqq_file1 <- "D:/datasets/pisa/2015/CSV/qqq/part-00040-01d07651-3143-4fa5-b265-c9487510be43-c000.csv"
qqq_file2 <- "D:/datasets/pisa/2015/CSV/qqq/part-00000-01d07651-3143-4fa5-b265-c9487510be43-c000.csv"
qqq_file3 <- "D:/datasets/pisa/2015/CSV/qqq/part-00039-01d07651-3143-4fa5-b265-c9487510be43-c000.csv"
library(readr)
??readr
?reader
?readr
library(haven)
library(readr)
library(dplyr)
read_csv(qqq:file1)
read_csv(qqq_file1)
read_csv(qqq_file2)
read_csv(qqq_file3)
qqq1 <- read_csv(qqq_file1)
qqq2 <- read_csv(qqq_file3)
qqq1 %>% bind_rows(qqq2)
dim(qqq1)
dim(qqq2)
rbind(qqq1, qqq2)
identical(rbind(qqq1, qqq2), bind_rows(qqq1, qqq2))
qqq <- bind_rows(qqq1, qqq2)
write_csv(qqq, "D:/datasets/pisa/2015/CSV/qqq_per.csv")
qqq2
?bind_rows
dim(qqq1)
qqq_file2 <- "D:/datasets/pisa/2015/CSV/qqq/part-00000-01d07651-3143-4fa5-b265-c9487510be43-c000.csv"
qqq3 <- read_csv(qqq_file2)
qqq_file2 <- "D:/datasets/pisa/2015/CSV/qqq/part-00000-01d07651-3143-4fa5-b265-c9487510be43-c000.csv"
qqq3 <- read_csv(qqq_file2)
bind_rows(qqq, qqq3)
identical(bind_rows(qqq, qqq3), qqq)
library(haven)
library(readr)
library(dplyr)
cog_file1 <- "D:/datasets/pisa/2015/CSV/cog/part-00097-f5b8c567-e45b-4071-a48c-d3c261b777a9-c000.csv"
cog_file2 <- "D:/datasets/pisa/2015/CSV/cog/part-00095-f5b8c567-e45b-4071-a48c-d3c261b777a9-c000.csv"
cog_file3 <- "D:/datasets/pisa/2015/CSV/cog/part-00096-f5b8c567-e45b-4071-a48c-d3c261b777a9-c000.csv"
cog1 <- read_csv(cog_file1)
cog2 <- read_csv(cog_file2)
cog3 <- read_csv(cog_file3)
write_csv(bind_rows(cog1, cog2, cog3), "D:/datasets/pisa/2015/CSV/cog_per.csv")
c(89, 72, 94, 69) -> a
(a-mean(a))/(max(a)-min(a))
1
?predict
mtcars
mtcars[1:6]
mtcars[1:6,]
lm(mpg ~ ., data = mtcars) -> modi
predict(modi, type = "terms")
predict(modi, type = "terms") -> kefue
typeof(kefue)
head(kefue)
predict(cyl = 1)
predict(modi, cyl = 1)
3!
factorial(3)
invo <- function(n){
s <- 0
for(i in 0:floor(n/2)){
s <- s + factorial(n)/((2**i)*factorial(i)*factorial(n - 2*i))
}
}
invo <- function(n){
s <- 0
for(i in 0:floor(n/2)){
s <- s + factorial(n)/((2**i)*factorial(i)*factorial(n - 2*i))
}
s
}
invo(1)
invo(12)
invo(2)
invo(3)
invo(4)
invo(5)
invo(6)
invo(7)
invo(8)
invo(9)
invo(10)
library(drake)
setwd("D:/gitrepos/tesis-pucpstat/tesis-rsrc/BayesChi2.R")
library(drake)
setwd("D:/gitrepos/tesis-pucpstat/tesis-rsrc")
library(drake)
loadd(simu.betab.data_0.2_seed0)
loadd(simu.betab.fit_simu.betab.data_0.2_seed0)
loadd(simu.betab.data_0.05_seed0)
loadd(simu.binom.fit_simu.betab.data_0.05_seed0)
